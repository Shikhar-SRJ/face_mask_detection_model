{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "protoPath = os.path.sep.join(\"/home/suraj/tensorflow/Notebooks/Face Mask/Face mask detector/face_detection_model\", \"deploy.prototxt\"])\n",
    "modelPath = os.path.sep.join(\"/home/suraj/tensorflow/Notebooks/Face Mask/Face mask detector/face_detection_model\", \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/suraj/tensorflow/Notebooks/Face Mask/Face mask detector/face_detection_model/\"\n",
    "protoPath = path + \"deploy.prototxt\"\n",
    "modelPath = path + \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/suraj/tensorflow/Notebooks/Face Mask/Face mask detector\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tflite.Interpreter(model_path='/home/suraj/tensorflow/Notebooks/Face Mask/Face mask detector/EnR_mask_detector_2.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'conv2d_1_input', 'index': 0, 'shape': array([  1, 200, 200,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}}] \n",
      "\n",
      " [{'name': 'Identity', 'index': 28, 'shape': array([1, 2], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}}]\n"
     ]
    }
   ],
   "source": [
    "print(input_details,'\\n\\n', output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9928185 0.0071815]]\n"
     ]
    }
   ],
   "source": [
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_clsfr = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "label_dict = {0:'MASK', 1:\"NO MASK\"}\n",
    "color_dict = {0:(0,255,0), 1:(0,0,255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.argmax(output_data, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "source= cv2.VideoCapture(0)\n",
    "sleep(2)\n",
    "\n",
    "img_size=224\n",
    "while True:\n",
    "    ret, img = source.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_clsfr.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for x, y, w ,h in faces:\n",
    "        face_img = img[y:y+h, x:x+w]\n",
    "        resized = cv2.resize(face_img, (img_size,img_size))\n",
    "        normalized = resized/255.0\n",
    "        reshaped = np.reshape(normalized, input_shape)\n",
    "        reshaped = np.float32(reshaped)\n",
    "        interpreter.set_tensor(input_details[0]['index'], reshaped)\n",
    "        interpreter.invoke()\n",
    "        result = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        label = np.argmax(result, axis=1)[0]\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h), color_dict[label], 2)\n",
    "#         cv2.rectangle(img,(x,y-4),(x+w,y), color_dict[label], -1)\n",
    "        cv2.putText(img, label_dict[label], (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "        cv2.putText(img, str(round(100*np.max(result),2))+ \"%\", (x+100,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "        \n",
    "    \n",
    "    cv2.imshow(\"LIVE\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if (key==27):\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "source= cv2.VideoCapture(0)\n",
    "sleep(2)\n",
    "\n",
    "img_size=200\n",
    "while True:\n",
    "    ret, img = source.read()\n",
    "    if ret:\n",
    "        frame = imutils.resize(img, width=600)\n",
    "        h, w = frame.shape[:2]\n",
    "        imageBlob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "        # apply OpenCV's deep learning-based face detector to localize\n",
    "        # faces in the input image\n",
    "        detector.setInput(imageBlob)\n",
    "        detections = detector.forward()\n",
    "\n",
    "        # loop over the detections\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated with\n",
    "            # the prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            # filter out weak detections\n",
    "            if confidence > 0.5:\n",
    "                # compute the (x, y)-coordinates of the bounding box for\n",
    "                # the face\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                # extract the face ROI\n",
    "                face = frame[startY:endY, startX:endX]\n",
    "                (fH, fW) = face.shape[:2]\n",
    "\n",
    "                # ensure the face width and height are sufficiently large\n",
    "                if fW < 20 or fH < 20:\n",
    "                    continue\n",
    "\n",
    "                # construct a blob for the face ROI, then pass the blob\n",
    "                # through our face embedding model to obtain the 128-d\n",
    "                # quantification of the face\n",
    "                faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "    \n",
    "                resized = cv2.resize(frame, (img_size,img_size))\n",
    "                normalized = resized/255.0\n",
    "                reshaped = np.reshape(normalized, input_shape)\n",
    "                reshaped = np.float32(reshaped)\n",
    "                interpreter.set_tensor(input_details[0]['index'], reshaped)\n",
    "                interpreter.invoke()\n",
    "                result = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "                label = np.argmax(result, axis=1)[0]\n",
    "        \n",
    "                cv2.rectangle(img,(startX, startY),(endX, endY), color_dict[label], 2)\n",
    "                cv2.putText(img, label_dict[label], (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "                cv2.putText(img, str(round(100*np.max(result),2))+ \"%\", (startX+100,startY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "                \n",
    "                cv2.imshow(\"LIVE\", img)\n",
    "                key = cv2.waitKey(1)\n",
    "    \n",
    "        if (key==27):\n",
    "            break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'conv2d_1_input',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 200, 200,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0}}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 224, 224,   3], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9936727 , 0.00632726]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54341894"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.54341894'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(np.max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
